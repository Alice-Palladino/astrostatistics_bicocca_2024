{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc55e83f-f177-4ba3-9297-4434b725a6b5",
   "metadata": {},
   "source": [
    "\n",
    "# Can a computer learn if we're going to detect gravitational waves?\n",
    "\n",
    "This episode of \"time to get your hands dirty\" is about something I studied carefully in the past: gravitational-wave selection effects.\n",
    "\n",
    "All experiments have selection effects. Some sources are easier to detect than others which distorts the population of sources we observe (this is crucial in astronomy! Surveys are typically flux limited). In order to decided if a feature in the observed population of objects is telling us something new about reality, we need to understand and model our selection effects (for instance: it would be wrong to say that all stars are close by just because we can't observe those that are very far!). In observational astronomy, this is known as Malmquist bias and was first formulated in 1922.\n",
    "\n",
    "The goal here is to machine-learn the LIGO detectability: can we predict if a gravitational-wave source will be detected?\n",
    "\n",
    "[This dataset](https://github.com/dgerosa/pdetclassifier/releases/download/v0.2/sample_2e7_design_precessing_higherordermodes_3detectors.h5) contains simulated gravitational-wave signals from merging black holes (careful the file size is >1 GB). If you've never seen them, the .h5 format is a highly optimized storage strategy for large datasets. It's amazing. In python, you can read it with h5py.\n",
    "\n",
    "In particular, each source has the following features:\n",
    "\n",
    "- mtot: the total mass of the binary\n",
    "- q: the mass ratio\n",
    "- chi1x, chi1y, chi1z, chi2x, chi2y, chi2z: the components of the black-hole spins in a suitable reference frame.\n",
    "- ra, dec: the location of the source in the sky\n",
    "- iota: the inclination of the orbital plane'\n",
    "- psi: the polarization angle (gravitational waves have two polarization states much like light)\n",
    "- z: the redshift\n",
    "\n",
    "The detectability is defined using the snr (signal-to-noise ratio) computed with a state-of-the-art model of the LIGO/Virgo detector network. Some (many?) of you will have studied this in Sesana's gravitational-wave course; see [here](https://arxiv.org/abs/1908.11170) for a nice write-up. All you need to know now is that we threshold the snr values and assume that LIGO will (not) see a source if snr>12 (snr<12). The resulting 0-1 labels are reported in the det attribute in the dataset.\n",
    "\n",
    "Today's task is to train a classifier (you decide which one!) and separate sources that are detectables from those that aren't.\n",
    "\n",
    "Be creative! This is a challenge! Let's see who gets the higher completeness and/or the smaller contamination (on a validation set, of course! Careful with overfitting here!).\n",
    "\n",
    "Tips:\n",
    "\n",
    "- You can downsample the data for debugging purposes\n",
    "- You can also use only some of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63523a6e-530b-4578-b468-87efbd7451f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "827083e8-50d4-4083-a5b1-146053d55c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['chi1x', 'chi1y', 'chi1z', 'chi2x', 'chi2y', 'chi2z', 'dec', 'det', 'iota', 'mtot', 'psi', 'q', 'ra', 'snr', 'z']>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = h5py.File('sample_2e7_design_precessing_higherordermodes_3detectors.h5')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2bcc692-2c40-4e45-89e4-25518399eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling the data\n",
    "N = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c857dfe2-05ef-49b7-a0b4-02dcde927f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "\n",
    "for label in ['chi1x', 'chi1y', 'chi1z', 'chi2x', 'chi2y', 'chi2z', 'dec', 'iota', 'mtot', 'psi', 'q', 'ra','z']:\n",
    "    \n",
    "    X.append(data[label][:N])\n",
    "    \n",
    "X = np.array(X).T\n",
    "y = np.array(data['det'][:N])     # 0 = snr < 12, 1 = snr >12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab5b8fa-3ea0-4040-8688-7d8fd2029d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05992903-cc99-4d4e-a063-cb8aa2249508",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=336)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6395833a-80eb-4667-b532-55f91dcdef06",
   "metadata": {},
   "source": [
    "\n",
    "## Basic decision tree\n",
    "\n",
    "First, we can start with a basic decision tree. We can use cross-validation to decide the best depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f4331d7-a828-415b-abee-19386cceb6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2d2f61efad4efe908902f01c790f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_splits = 5\n",
    "\n",
    "depths_range = np.arange(1, 21, dtype = int)\n",
    "\n",
    "accuracy_cv_array = np.empty(len(depths_range))\n",
    "precision_cv_array = np.empty(len(depths_range))\n",
    "completeness_cv_array = np.empty(len(depths_range))\n",
    "\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=336)\n",
    "\n",
    "for i, depth in tqdm(enumerate(depths_range), total = len(depths_range)):\n",
    "    \n",
    "    dtc = DecisionTreeClassifier(max_depth = depth, criterion = 'entropy', random_state = 336)\n",
    "    \n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    completeness = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train_cv, X_test_cv = X_train[train_index], X_train[test_index]\n",
    "        y_train_cv, y_test_cv = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        # Leaving X_test and y_test for the final evaluation\n",
    "        \n",
    "        dtc.fit(X_train_cv, y_train_cv)\n",
    "        y_pred_test_cv = dtc.predict(X_test_cv)\n",
    "        \n",
    "        accuracy.append(accuracy_score(y_test_cv, y_pred_test_cv))\n",
    "        precision.append(precision_score(y_test_cv, y_pred_test_cv))\n",
    "        completeness.append(recall_score(y_test_cv, y_pred_test_cv))\n",
    "\n",
    "    accuracy_cv_array[i] = np.mean(accuracy)\n",
    "    precision_cv_array[i] = np.mean(precision)\n",
    "    completeness_cv_array[i] = np.mean(completeness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ba67bfc-9394-4c75-b370-a9717b3af850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92288571, 0.92781429, 0.93218571, 0.9429    , 0.94497143,\n",
       "       0.9485    , 0.95027143, 0.95701429, 0.95665714, 0.95651429,\n",
       "       0.95582857, 0.95528571, 0.95428571, 0.95342857, 0.9531    ,\n",
       "       0.95224286, 0.95162857, 0.95178571, 0.95117143, 0.95105714])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eac8a5a-fa17-4031-89d7-6057283bfeb1",
   "metadata": {},
   "source": [
    "Note: since this is an unbalanced dataset, getting a high accuracy doesn't automatically mean that we used the best classifier; therefore, we can also try using contamination* and completeness as the score for the CV.\n",
    "\n",
    "_*Computed as 1-precision, so that we can maximize all the scores to find the best hyperparameters._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62cb8d52-2c49-4b83-951e-c7c1682ce7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67871876, 0.91711058, 0.7538054 , 0.78234661, 0.86056539,\n",
       "       0.80799546, 0.86252829, 0.86049969, 0.84792979, 0.85438894,\n",
       "       0.84796288, 0.85068202, 0.8441197 , 0.8413222 , 0.84125028,\n",
       "       0.83583236, 0.83394462, 0.83395785, 0.83075849, 0.83032713])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_cv_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5830565-7f65-4829-bca4-a2808ab31ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87657859, 0.5456406 , 0.81183532, 0.8332702 , 0.73916987,\n",
       "       0.84026065, 0.77786292, 0.8356673 , 0.84999166, 0.839558  ,\n",
       "       0.84286386, 0.83436587, 0.83509389, 0.83169829, 0.82899742,\n",
       "       0.82954593, 0.82695165, 0.82829003, 0.82781216, 0.82740958])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_cv_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2aaccfe-f422-4820-8b5d-8c9f1470d66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depths considered:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "\n",
      "Scoring metric: Accuracy\n",
      " Best depth: 8\n",
      "\n",
      "Scoring metric: Contamination\n",
      " Best depth: 2\n",
      "\n",
      "Scoring metric: Completeness\n",
      " Best depth: 1\n"
     ]
    }
   ],
   "source": [
    "print('Depths considered:')\n",
    "print(depths_range)\n",
    "\n",
    "scoring_metrics = ['Accuracy', 'Contamination', 'Completeness']\n",
    "cv_arrays = [accuracy_cv_array, precision_cv_array, completeness_cv_array]\n",
    "\n",
    "best_depths_dtc = np.empty(3)\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    best_index = np.argmax(cv_arrays[i])   \n",
    "    best_depths_dtc[i] = depths_range[best_index]\n",
    "    print('\\nScoring metric: ' + str(scoring_metrics[i]))\n",
    "    print(' Best depth: %i' % best_depths_dtc[i]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb267c78-388d-4d0b-ae50-e85d2de65a6e",
   "metadata": {},
   "source": [
    "With this values, we can see how the Decision Tree performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fb9c324-01aa-4958-8adf-ceb4b87e6136",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_train_dtc = np.empty(3)\n",
    "contaminations_train_dtc = np.empty(3)\n",
    "completenesses_train_dtc = np.empty(3)\n",
    "tp_train_dtc = np.empty(3)\n",
    "fp_train_dtc = np.empty(3)\n",
    "fn_train_dtc = np.empty(3)\n",
    "tn_train_dtc = np.empty(3)\n",
    "\n",
    "accuracies_test_dtc = np.empty(3)\n",
    "contaminations_test_dtc = np.empty(3)\n",
    "completenesses_test_dtc = np.empty(3)\n",
    "tp_test_dtc = np.empty(3)\n",
    "fp_test_dtc = np.empty(3)\n",
    "fn_test_dtc = np.empty(3)\n",
    "tn_test_dtc = np.empty(3)\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    dtc = DecisionTreeClassifier(max_depth = int(best_depths_dtc[i]), random_state = 336)\n",
    "    dtc.fit(X_train, y_train)\n",
    "    y_train_pred = dtc.predict(X_train)\n",
    "    y_test_pred = dtc.predict(X_test)\n",
    "\n",
    "    accuracies_train_dtc[i] = accuracy_score(y_train, y_train_pred)\n",
    "    contaminations_train_dtc[i] = 1 - precision_score(y_train, y_train_pred)\n",
    "    completenesses_train_dtc[i] = recall_score(y_train, y_train_pred)\n",
    "    conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "    tn_train_dtc[i], fp_train_dtc[i], fn_train_dtc[i], tp_train_dtc[i] = conf_matrix_train.ravel()\n",
    "    \n",
    "    accuracies_test_dtc[i] = accuracy_score(y_test, y_test_pred)\n",
    "    contaminations_test_dtc[i] = 1 - precision_score(y_test, y_test_pred)\n",
    "    completenesses_test_dtc[i] = recall_score(y_test, y_test_pred)\n",
    "    conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "    tn_test_dtc[i], fp_test_dtc[i], fn_test_dtc[i], tp_test_dtc[i] = conf_matrix_test.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21c92158-74f6-4969-8b35-c5574438c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table_dtc = pd.DataFrame({\n",
    "    'Scoring metric for CV': scoring_metrics,\n",
    "    'Max_depth': best_depths_dtc,\n",
    "    'Accuracy': accuracies_train_dtc,\n",
    "    'Contamination': contaminations_train_dtc,\n",
    "    'Completeness': completenesses_train_dtc,\n",
    "    'True positives': tp_train_dtc,\n",
    "    'False positives': fp_train_dtc,\n",
    "    'False negatives': fn_train_dtc,\n",
    "    'True negatives': tn_train_dtc\n",
    "})\n",
    "\n",
    "train_table_dtc[['Accuracy', 'Contamination', 'Completeness']] = train_table_dtc[['Accuracy', 'Contamination', 'Completeness']].round(3)\n",
    "train_table_dtc[['Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']] = train_table_dtc[['Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "test_table_dtc = pd.DataFrame({\n",
    "    'Scoring metric for CV': scoring_metrics,\n",
    "    'Max_depth': best_depths_dtc,\n",
    "    'Accuracy': accuracies_test_dtc,\n",
    "    'Contamination': contaminations_test_dtc,\n",
    "    'Completeness': completenesses_test_dtc,\n",
    "    'True positives': tp_test_dtc,\n",
    "    'False positives': fp_test_dtc,\n",
    "    'False negatives': fn_test_dtc,\n",
    "    'True negatives': tn_test_dtc\n",
    "})\n",
    "\n",
    "test_table_dtc[['Accuracy', 'Contamination', 'Completeness']] = test_table_dtc[['Accuracy', 'Contamination', 'Completeness']].round(3)\n",
    "test_table_dtc[['Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']] = test_table_dtc[['Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19151a99-00bd-4a99-a293-bcba00b5299d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Results of simple decision tree classification on train dataset:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scoring metric for CV</th>\n",
       "      <th>Max_depth</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>True positives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "      <th>True negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>8</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.883</td>\n",
       "      <td>8854</td>\n",
       "      <td>1194</td>\n",
       "      <td>1168</td>\n",
       "      <td>58784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contamination</td>\n",
       "      <td>2</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.788</td>\n",
       "      <td>7901</td>\n",
       "      <td>2363</td>\n",
       "      <td>2121</td>\n",
       "      <td>57615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Completeness</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.788</td>\n",
       "      <td>7901</td>\n",
       "      <td>2363</td>\n",
       "      <td>2121</td>\n",
       "      <td>57615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scoring metric for CV  Max_depth  Accuracy  Contamination  Completeness  \\\n",
       "0              Accuracy          8     0.966          0.119         0.883   \n",
       "1         Contamination          2     0.936          0.230         0.788   \n",
       "2          Completeness          1     0.936          0.230         0.788   \n",
       "\n",
       "   True positives  False positives  False negatives  True negatives  \n",
       "0            8854             1194             1168           58784  \n",
       "1            7901             2363             2121           57615  \n",
       "2            7901             2363             2121           57615  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Results of simple decision tree classification on test dataset:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scoring metric for CV</th>\n",
       "      <th>Max_depth</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>True positives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "      <th>True negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>8</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.853</td>\n",
       "      <td>3719</td>\n",
       "      <td>635</td>\n",
       "      <td>641</td>\n",
       "      <td>25005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contamination</td>\n",
       "      <td>2</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.788</td>\n",
       "      <td>3435</td>\n",
       "      <td>1036</td>\n",
       "      <td>925</td>\n",
       "      <td>24604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Completeness</td>\n",
       "      <td>1</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.788</td>\n",
       "      <td>3435</td>\n",
       "      <td>1036</td>\n",
       "      <td>925</td>\n",
       "      <td>24604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scoring metric for CV  Max_depth  Accuracy  Contamination  Completeness  \\\n",
       "0              Accuracy          8     0.957          0.146         0.853   \n",
       "1         Contamination          2     0.935          0.232         0.788   \n",
       "2          Completeness          1     0.935          0.232         0.788   \n",
       "\n",
       "   True positives  False positives  False negatives  True negatives  \n",
       "0            3719              635              641           25005  \n",
       "1            3435             1036              925           24604  \n",
       "2            3435             1036              925           24604  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"### Results of simple decision tree classification on train dataset:\"))\n",
    "display(train_table_dtc)\n",
    "\n",
    "display(Markdown(\"### Results of simple decision tree classification on test dataset:\"))\n",
    "display(test_table_dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b072171-fe97-4078-b981-9703fd04a486",
   "metadata": {},
   "source": [
    "For this particular split of train and test data, max_depth = 1 and max_depth = 2 yield the same results in terms of cross-validation with contamination and completeness as scoring metrics. The best classifier out of these is clearly the one with the best accuracy, so the decision tree with max_depth = 8.\n",
    "\n",
    "To improve the performance, we can try bagging and a random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb42d5d-74ea-40d7-a823-d81d133dfb22",
   "metadata": {},
   "source": [
    "\n",
    "## Bagged decision tree\n",
    "\n",
    "We'll cross-validate on the depth and the number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9ac05e6-9b17-4e31-b4d2-a929988a4ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bbfdeaa9cc4f0bafde3622b8905823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f550ca22a7594bb6a5ad5aadef2445a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7a020d82a24aeaae6bed62a4fb14d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c8441c32144d37b18576b9f51ac8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_splits = 5\n",
    "\n",
    "n_range = [5, 10, 15]\n",
    "depths_range = np.arange(1, 11, dtype = int)\n",
    "\n",
    "accuracy_cv_matrix = np.empty((len(n_range), len(depths_range)))\n",
    "precision_cv_matrix = np.empty((len(n_range), len(depths_range)))\n",
    "completeness_cv_matrix = np.empty((len(n_range), len(depths_range)))\n",
    "\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=336)\n",
    "\n",
    "for i, ntrees in tqdm(enumerate(n_range), total = len(n_range)):\n",
    "\n",
    "    for j, depth in tqdm(enumerate(depths_range), total = len(depths_range)):\n",
    "    \n",
    "        dtc = DecisionTreeClassifier(max_depth = depth, criterion = 'entropy', random_state = 336)\n",
    "        bag_dtc = BaggingClassifier(estimator = dtc,  n_estimators = ntrees, random_state=336, n_jobs=-1)\n",
    "        \n",
    "        accuracy = []\n",
    "        precision = []\n",
    "        completeness = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(X_train):\n",
    "            X_train_cv, X_test_cv = X_train[train_index], X_train[test_index]\n",
    "            y_train_cv, y_test_cv = y_train[train_index], y_train[test_index]\n",
    "            \n",
    "            bag_dtc.fit(X_train_cv, y_train_cv)\n",
    "            y_pred_test_cv = bag_dtc.predict(X_test_cv)\n",
    "            \n",
    "            accuracy.append(accuracy_score(y_test_cv, y_pred_test_cv))\n",
    "            precision.append(precision_score(y_test_cv, y_pred_test_cv, zero_division=0))\n",
    "            completeness.append(recall_score(y_test_cv, y_pred_test_cv))\n",
    "    \n",
    "        accuracy_cv_matrix[i, j] = np.mean(accuracy)\n",
    "        precision_cv_matrix[i, j] = np.mean(precision)\n",
    "        completeness_cv_matrix[i, j] = np.mean(completeness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80b61de4-96a3-4e3b-9e9e-3126d462fe63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92375714, 0.93031429, 0.93461429, 0.94435714, 0.94817143,\n",
       "        0.95298571, 0.95944286, 0.96104286, 0.96191429, 0.96208571],\n",
       "       [0.92328571, 0.93332857, 0.93537143, 0.94412857, 0.94964286,\n",
       "        0.95255714, 0.96007143, 0.9616    , 0.9632    , 0.96361429],\n",
       "       [0.92334286, 0.93277143, 0.936     , 0.94494286, 0.94985714,\n",
       "        0.9533    , 0.96091429, 0.96212857, 0.9635    , 0.964     ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de375c6d-b349-4366-b72c-a3e8023bf100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68272787, 0.85566343, 0.73349494, 0.79381455, 0.83000936,\n",
       "        0.84922077, 0.87497661, 0.88251617, 0.88184612, 0.88242111],\n",
       "       [0.68056292, 0.88852456, 0.73769826, 0.79183526, 0.83310452,\n",
       "        0.84338933, 0.87861728, 0.88640935, 0.88702715, 0.88736915],\n",
       "       [0.68081406, 0.8916935 , 0.7637933 , 0.79575397, 0.83355968,\n",
       "        0.85080394, 0.8856288 , 0.88795157, 0.8883553 , 0.88793745]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "469f6a4f-e404-4e97-b5fd-e1fe01fd8f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87419794, 0.64547952, 0.8545796 , 0.82688731, 0.80463658,\n",
       "        0.81682339, 0.83652495, 0.83989092, 0.84767694, 0.84829108],\n",
       "       [0.87535505, 0.61155753, 0.85183569, 0.8278436 , 0.81125138,\n",
       "        0.82144106, 0.83721522, 0.83954869, 0.85156759, 0.85437314],\n",
       "       [0.87515854, 0.60418957, 0.81343538, 0.82826542, 0.81250576,\n",
       "        0.81739769, 0.83509512, 0.84188983, 0.85226707, 0.85679936]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bfff53e-275e-42f7-bd63-b2cdc0891ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of trees considered:\n",
      "[5, 10, 15]\n",
      "Depths considered:\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "\n",
      "Scoring metric: Accuracy\n",
      " Best number of trees: 15\n",
      " Best max_depth: 10\n",
      "\n",
      "Scoring metric: Contamination\n",
      " Best number of trees: 15\n",
      " Best max_depth: 2\n",
      "\n",
      "Scoring metric: Completeness\n",
      " Best number of trees: 10\n",
      " Best max_depth: 1\n"
     ]
    }
   ],
   "source": [
    "print('Numbers of trees considered:')\n",
    "print(n_range)\n",
    "\n",
    "print('Depths considered:')\n",
    "print(depths_range)\n",
    "\n",
    "cv_matrices = [accuracy_cv_matrix, precision_cv_matrix, completeness_cv_matrix]\n",
    "\n",
    "best_n_est_bag = np.empty(3)\n",
    "best_depths_bag = np.empty(3)\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    best_index_flat = np.argmax(cv_matrices[i]) \n",
    "    best_index_2d = np.unravel_index(best_index_flat, cv_matrices[i].shape)\n",
    "    \n",
    "    best_n_est_bag[i] = n_range[best_index_2d[0]]\n",
    "    best_depths_bag[i] = depths_range[best_index_2d[1]]\n",
    "    \n",
    "    print('\\nScoring metric: ' + str(scoring_metrics[i]))\n",
    "    print(' Best number of trees: %i' % best_n_est_bag[i]) \n",
    "    print(' Best max_depth: %i' % best_depths_bag[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22415852-0f04-4663-9cec-6ddde78d7460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e437504a454e0580356490c57d8a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies_train_bag = np.empty(3)\n",
    "contaminations_train_bag = np.empty(3)\n",
    "completenesses_train_bag = np.empty(3)\n",
    "tp_train_bag = np.empty(3)\n",
    "fp_train_bag = np.empty(3)\n",
    "fn_train_bag = np.empty(3)\n",
    "tn_train_bag = np.empty(3)\n",
    "\n",
    "accuracies_test_bag = np.empty(3)\n",
    "contaminations_test_bag = np.empty(3)\n",
    "completenesses_test_bag = np.empty(3)\n",
    "tp_test_bag = np.empty(3)\n",
    "fp_test_bag = np.empty(3)\n",
    "fn_test_bag = np.empty(3)\n",
    "tn_test_bag = np.empty(3)\n",
    "\n",
    "for (i, ntrees), depth in tqdm(zip(enumerate(best_n_est_bag), best_depths_bag), total=len(best_n_est_bag)):\n",
    "\n",
    "    dtc = DecisionTreeClassifier(max_depth = int(depth), criterion = 'entropy', random_state = 336)\n",
    "    bag_dtc = BaggingClassifier(estimator = dtc,  n_estimators = int(ntrees), random_state=336, n_jobs=-1)\n",
    "    bag_dtc.fit(X_train, y_train)\n",
    "    y_train_pred = bag_dtc.predict(X_train)\n",
    "    y_test_pred = bag_dtc.predict(X_test)\n",
    "\n",
    "    accuracies_train_bag[i] = accuracy_score(y_train, y_train_pred)\n",
    "    contaminations_train_bag[i] = 1 - precision_score(y_train, y_train_pred)\n",
    "    completenesses_train_bag[i] = recall_score(y_train, y_train_pred)\n",
    "    conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "    tn_train_bag[i], fp_train_bag[i], fn_train_bag[i], tp_train_bag[i] = conf_matrix_train.ravel()\n",
    "    \n",
    "    accuracies_test_bag[i] = accuracy_score(y_test, y_test_pred)\n",
    "    contaminations_test_bag[i] = 1 - precision_score(y_test, y_test_pred)\n",
    "    completenesses_test_bag[i] = recall_score(y_test, y_test_pred)\n",
    "    conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "    tn_test_bag[i], fp_test_bag[i], fn_test_bag[i], tp_test_bag[i] = conf_matrix_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77619c6a-5f89-46dc-be5a-09cd27aff585",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table_bag = pd.DataFrame({\n",
    "    'Scoring metric for CV': scoring_metrics,\n",
    "    'Number of trees': best_n_est_bag,\n",
    "    'Max_depth': best_depths_bag,\n",
    "    'Accuracy': accuracies_train_bag,\n",
    "    'Contamination': contaminations_train_bag,\n",
    "    'Completeness': completenesses_train_bag,\n",
    "    'True positives': tp_train_bag,\n",
    "    'False positives': fp_train_bag,\n",
    "    'False negatives': fn_train_bag,\n",
    "    'True negatives': tn_train_bag\n",
    "})\n",
    "\n",
    "train_table_bag[['Accuracy', 'Contamination', 'Completeness']] = train_table_bag[['Accuracy', 'Contamination', 'Completeness']].round(3)\n",
    "train_table_bag[['Number of trees', 'Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']] = train_table_bag[['Number of trees', 'Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "test_table_bag = pd.DataFrame({\n",
    "    'Scoring metric for CV': scoring_metrics,\n",
    "    'Number of trees': best_n_est_bag,\n",
    "    'Max_depth': best_depths_bag,\n",
    "    'Accuracy': accuracies_test_bag,\n",
    "    'Contamination': contaminations_test_bag,\n",
    "    'Completeness': completenesses_test_bag,\n",
    "    'True positives': tp_test_bag,\n",
    "    'False positives': fp_test_bag,\n",
    "    'False negatives': fn_test_bag,\n",
    "    'True negatives': tn_test_bag\n",
    "})\n",
    "\n",
    "test_table_bag[['Accuracy', 'Contamination', 'Completeness']] = test_table_bag[['Accuracy', 'Contamination', 'Completeness']].round(3)\n",
    "test_table_bag[['Number of trees', 'Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']] = test_table_bag[['Number of trees', 'Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b54b047-263b-449e-ba48-5caf0f849ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Results of bagged decision tree classification on train dataset:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scoring metric for CV</th>\n",
       "      <th>Number of trees</th>\n",
       "      <th>Max_depth</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>True positives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "      <th>True negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.906</td>\n",
       "      <td>9078</td>\n",
       "      <td>766</td>\n",
       "      <td>944</td>\n",
       "      <td>59212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contamination</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.602</td>\n",
       "      <td>6038</td>\n",
       "      <td>700</td>\n",
       "      <td>3984</td>\n",
       "      <td>59278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Completeness</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.872</td>\n",
       "      <td>8738</td>\n",
       "      <td>3990</td>\n",
       "      <td>1284</td>\n",
       "      <td>55988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scoring metric for CV  Number of trees  Max_depth  Accuracy  Contamination  \\\n",
       "0              Accuracy               15         10     0.976          0.078   \n",
       "1         Contamination               15          2     0.933          0.104   \n",
       "2          Completeness               10          1     0.925          0.313   \n",
       "\n",
       "   Completeness  True positives  False positives  False negatives  \\\n",
       "0         0.906            9078              766              944   \n",
       "1         0.602            6038              700             3984   \n",
       "2         0.872            8738             3990             1284   \n",
       "\n",
       "   True negatives  \n",
       "0           59212  \n",
       "1           59278  \n",
       "2           55988  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Results of bagged decision tree classification on test dataset:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scoring metric for CV</th>\n",
       "      <th>Number of trees</th>\n",
       "      <th>Max_depth</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>True positives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "      <th>True negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.852</td>\n",
       "      <td>3714</td>\n",
       "      <td>492</td>\n",
       "      <td>646</td>\n",
       "      <td>25148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contamination</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.607</td>\n",
       "      <td>2646</td>\n",
       "      <td>301</td>\n",
       "      <td>1714</td>\n",
       "      <td>25339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Completeness</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.869</td>\n",
       "      <td>3789</td>\n",
       "      <td>1813</td>\n",
       "      <td>571</td>\n",
       "      <td>23827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scoring metric for CV  Number of trees  Max_depth  Accuracy  Contamination  \\\n",
       "0              Accuracy               15         10     0.962          0.117   \n",
       "1         Contamination               15          2     0.933          0.102   \n",
       "2          Completeness               10          1     0.921          0.324   \n",
       "\n",
       "   Completeness  True positives  False positives  False negatives  \\\n",
       "0         0.852            3714              492              646   \n",
       "1         0.607            2646              301             1714   \n",
       "2         0.869            3789             1813              571   \n",
       "\n",
       "   True negatives  \n",
       "0           25148  \n",
       "1           25339  \n",
       "2           23827  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"### Results of bagged decision tree classification on train dataset:\"))\n",
    "display(train_table_bag)\n",
    "\n",
    "display(Markdown(\"### Results of bagged decision tree classification on test dataset:\"))\n",
    "display(test_table_bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46a96a-6982-4382-bcac-033cb22f58bf",
   "metadata": {},
   "source": [
    "The results of the bagged decision tree classifier are slightly better than the ones for the single decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c829ac4-1f66-402b-86c3-01cc702065cb",
   "metadata": {},
   "source": [
    "\n",
    "## Random forest\n",
    "\n",
    "We'll cross-validate on the same parameters as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80fc83e1-62e8-4794-b038-0719f100c677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1ed225490b439aab4d471cb8037918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf21b958e584ba9b297af33075f56e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78955a4a6b9e46e19dfae9ebf2dad6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54cf7233d574eae8987ff4d62b4ec6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_splits = 5\n",
    "\n",
    "n_range = [50, 100, 200]\n",
    "depths_range = np.arange(8, 14, dtype = int)\n",
    "# Note: I've chosen this range for the depths because I've tried various ranges and they all went into overfitting, so I \n",
    "# decreased the max_depth allowed and increased min_samples_split from 2 to 20 to avoid it; since the trees always wanted\n",
    "# to go to the maximum possible depth, I've abandoned the first values to decrease computational costs.\n",
    "\n",
    "accuracy_cv_matrix = np.empty((len(n_range), len(depths_range)))\n",
    "precision_cv_matrix = np.empty((len(n_range), len(depths_range)))\n",
    "completeness_cv_matrix = np.empty((len(n_range), len(depths_range)))\n",
    "\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=336)\n",
    "\n",
    "for i, ntrees in tqdm(enumerate(n_range), total = len(n_range)):\n",
    "\n",
    "    for j, depth in tqdm(enumerate(depths_range), total = len(depths_range)):\n",
    "    \n",
    "        rand_for = RandomForestClassifier(max_depth = depth, n_estimators = ntrees, min_samples_split = 20, criterion = 'entropy', random_state = 336, n_jobs = -1)\n",
    "        \n",
    "        accuracy = []\n",
    "        precision = []\n",
    "        completeness = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(X_train):\n",
    "            X_train_cv, X_test_cv = X_train[train_index], X_train[test_index]\n",
    "            y_train_cv, y_test_cv = y_train[train_index], y_train[test_index]\n",
    "            \n",
    "            rand_for.fit(X_train_cv, y_train_cv)\n",
    "            y_pred_test_cv = rand_for.predict(X_test_cv)\n",
    "            \n",
    "            accuracy.append(accuracy_score(y_test_cv, y_pred_test_cv))\n",
    "            precision.append(precision_score(y_test_cv, y_pred_test_cv, zero_division=0))\n",
    "            completeness.append(recall_score(y_test_cv, y_pred_test_cv))\n",
    "    \n",
    "        accuracy_cv_matrix[i, j] = np.mean(accuracy)\n",
    "        precision_cv_matrix[i, j] = np.mean(precision)\n",
    "        completeness_cv_matrix[i, j] = np.mean(completeness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd09fcda-2a90-465d-b762-7713d1cf8860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95871429, 0.95978571, 0.96101429, 0.96181429, 0.96317143,\n",
       "        0.96382857],\n",
       "       [0.95894286, 0.96      , 0.9612    , 0.96227143, 0.96347143,\n",
       "        0.96371429],\n",
       "       [0.95921429, 0.96021429, 0.96102857, 0.96224286, 0.96348571,\n",
       "        0.96387143]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a80a253b-8854-4c78-bf8e-a1d826caeedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89350313, 0.90049964, 0.89724531, 0.89486253, 0.901838  ,\n",
       "        0.90201185],\n",
       "       [0.89068323, 0.89356691, 0.89449967, 0.89756033, 0.90193162,\n",
       "        0.9002779 ],\n",
       "       [0.88886193, 0.89211263, 0.8935316 , 0.898593  , 0.90145566,\n",
       "        0.90063753]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5cb5055-9f5a-4162-9c4b-310b9f4c91ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80805759, 0.808849  , 0.82209953, 0.83115859, 0.83371785,\n",
       "        0.83863859],\n",
       "       [0.81318663, 0.81835885, 0.82674693, 0.83158506, 0.83591351,\n",
       "        0.83974763],\n",
       "       [0.8174889 , 0.82164038, 0.82646467, 0.83015075, 0.83662742,\n",
       "        0.84055285]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5f59b6e-1264-4e96-a869-4985cb9070ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of estimators considered:\n",
      "[50, 100, 200]\n",
      "Depths considered:\n",
      "[ 8  9 10 11 12 13]\n",
      "\n",
      "Scoring metric: Accuracy\n",
      " Best number of estimators: 200.00\n",
      " Best max_depth: 13\n",
      "\n",
      "Scoring metric: Contamination\n",
      " Best number of estimators: 50.00\n",
      " Best max_depth: 13\n",
      "\n",
      "Scoring metric: Completeness\n",
      " Best number of estimators: 200.00\n",
      " Best max_depth: 13\n"
     ]
    }
   ],
   "source": [
    "print('Numbers of estimators considered:')\n",
    "print(n_range)\n",
    "\n",
    "print('Depths considered:')\n",
    "print(depths_range)\n",
    "\n",
    "cv_matrices = [accuracy_cv_matrix, precision_cv_matrix, completeness_cv_matrix]\n",
    "\n",
    "best_n_est_ran = np.empty(3)\n",
    "best_depths_ran = np.empty(3)\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    best_index_flat = np.argmax(cv_matrices[i]) \n",
    "    best_index_2d = np.unravel_index(best_index_flat, cv_matrices[i].shape)\n",
    "    \n",
    "    best_n_est_ran[i] = n_range[best_index_2d[0]]\n",
    "    best_depths_ran[i] = depths_range[best_index_2d[1]]\n",
    "    \n",
    "    print('\\nScoring metric: ' + str(scoring_metrics[i]))\n",
    "    print(' Best number of estimators: %.2f' % best_n_est_ran[i]) \n",
    "    print(' Best max_depth: %i' % best_depths_ran[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68cea157-8d19-4676-87e0-c60ba2ab460d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1080e351104994842188d76722e296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies_train_ran = np.empty(3)\n",
    "contaminations_train_ran = np.empty(3)\n",
    "completenesses_train_ran = np.empty(3)\n",
    "tp_train_ran = np.empty(3)\n",
    "fp_train_ran = np.empty(3)\n",
    "fn_train_ran = np.empty(3)\n",
    "tn_train_ran = np.empty(3)\n",
    "\n",
    "accuracies_test_ran = np.empty(3)\n",
    "contaminations_test_ran = np.empty(3)\n",
    "completenesses_test_ran = np.empty(3)\n",
    "tp_test_ran = np.empty(3)\n",
    "fp_test_ran = np.empty(3)\n",
    "fn_test_ran = np.empty(3)\n",
    "tn_test_ran = np.empty(3)\n",
    "\n",
    "for (i, ntrees), depth in tqdm(zip(enumerate(best_n_est_ran), best_depths_ran), total=len(best_n_est_ran)):\n",
    "\n",
    "    rand_for = RandomForestClassifier(max_depth = int(depth), n_estimators = int(ntrees), criterion = 'entropy', random_state = 336, n_jobs = -1)\n",
    "    rand_for.fit(X_train, y_train)\n",
    "    y_train_pred = rand_for.predict(X_train)\n",
    "    y_test_pred = rand_for.predict(X_test)\n",
    "\n",
    "    accuracies_train_ran[i] = accuracy_score(y_train, y_train_pred)\n",
    "    contaminations_train_ran[i] = 1 - precision_score(y_train, y_train_pred)\n",
    "    completenesses_train_ran[i] = recall_score(y_train, y_train_pred)\n",
    "    conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "    tn_train_ran[i], fp_train_ran[i], fn_train_ran[i], tp_train_ran[i] = conf_matrix_train.ravel()\n",
    "    \n",
    "    accuracies_test_ran[i] = accuracy_score(y_test, y_test_pred)\n",
    "    contaminations_test_ran[i] = 1 - precision_score(y_test, y_test_pred)\n",
    "    completenesses_test_ran[i] = recall_score(y_test, y_test_pred)\n",
    "    conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "    tn_test_ran[i], fp_test_ran[i], fn_test_ran[i], tp_test_ran[i] = conf_matrix_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46910ba7-6e63-4bb0-a6e0-9c18893c2b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table_ran = pd.DataFrame({\n",
    "    'Scoring metric for CV': scoring_metrics,\n",
    "    'Number of trees': best_n_est_ran,\n",
    "    'Max_depth': best_depths_ran,\n",
    "    'Accuracy': accuracies_train_ran,\n",
    "    'Contamination': contaminations_train_ran,\n",
    "    'Completeness': completenesses_train_ran,\n",
    "    'True positives': tp_train_ran,\n",
    "    'False positives': fp_train_ran,\n",
    "    'False negatives': fn_train_ran,\n",
    "    'True negatives': tn_train_ran\n",
    "})\n",
    "\n",
    "train_table_ran[['Accuracy', 'Contamination', 'Completeness']] = train_table_ran[['Accuracy', 'Contamination', 'Completeness']].round(3)\n",
    "train_table_ran[['Number of trees', 'Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']] = train_table_ran[['Number of trees', 'Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "test_table_ran = pd.DataFrame({\n",
    "    'Scoring metric for CV': scoring_metrics,\n",
    "    'Number of trees': best_n_est_ran,\n",
    "    'Max_depth': best_depths_ran,\n",
    "    'Accuracy': accuracies_test_ran,\n",
    "    'Contamination': contaminations_test_ran,\n",
    "    'Completeness': completenesses_test_ran,\n",
    "    'True positives': tp_test_ran,\n",
    "    'False positives': fp_test_ran,\n",
    "    'False negatives': fn_test_ran,\n",
    "    'True negatives': tn_test_ran\n",
    "})\n",
    "\n",
    "test_table_ran[['Accuracy', 'Contamination', 'Completeness']] = test_table_ran[['Accuracy', 'Contamination', 'Completeness']].round(3)\n",
    "test_table_ran[['Number of trees', 'Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']] = test_table_ran[['Number of trees', 'Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcc8668a-aed8-4d63-abdf-f911d843b971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Results of random forest classification on train dataset:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scoring metric for CV</th>\n",
       "      <th>Number of trees</th>\n",
       "      <th>Max_depth</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>True positives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "      <th>True negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>200</td>\n",
       "      <td>13</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.927</td>\n",
       "      <td>9290</td>\n",
       "      <td>410</td>\n",
       "      <td>732</td>\n",
       "      <td>59568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contamination</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.924</td>\n",
       "      <td>9258</td>\n",
       "      <td>401</td>\n",
       "      <td>764</td>\n",
       "      <td>59577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Completeness</td>\n",
       "      <td>200</td>\n",
       "      <td>13</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.927</td>\n",
       "      <td>9290</td>\n",
       "      <td>410</td>\n",
       "      <td>732</td>\n",
       "      <td>59568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scoring metric for CV  Number of trees  Max_depth  Accuracy  Contamination  \\\n",
       "0              Accuracy              200         13     0.984          0.042   \n",
       "1         Contamination               50         13     0.983          0.042   \n",
       "2          Completeness              200         13     0.984          0.042   \n",
       "\n",
       "   Completeness  True positives  False positives  False negatives  \\\n",
       "0         0.927            9290              410              732   \n",
       "1         0.924            9258              401              764   \n",
       "2         0.927            9290              410              732   \n",
       "\n",
       "   True negatives  \n",
       "0           59568  \n",
       "1           59577  \n",
       "2           59568  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Results of random forest classification on test dataset:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scoring metric for CV</th>\n",
       "      <th>Number of trees</th>\n",
       "      <th>Max_depth</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>True positives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "      <th>True negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>200</td>\n",
       "      <td>13</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.842</td>\n",
       "      <td>3669</td>\n",
       "      <td>417</td>\n",
       "      <td>691</td>\n",
       "      <td>25223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contamination</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.840</td>\n",
       "      <td>3661</td>\n",
       "      <td>425</td>\n",
       "      <td>699</td>\n",
       "      <td>25215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Completeness</td>\n",
       "      <td>200</td>\n",
       "      <td>13</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.842</td>\n",
       "      <td>3669</td>\n",
       "      <td>417</td>\n",
       "      <td>691</td>\n",
       "      <td>25223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scoring metric for CV  Number of trees  Max_depth  Accuracy  Contamination  \\\n",
       "0              Accuracy              200         13     0.963          0.102   \n",
       "1         Contamination               50         13     0.963          0.104   \n",
       "2          Completeness              200         13     0.963          0.102   \n",
       "\n",
       "   Completeness  True positives  False positives  False negatives  \\\n",
       "0         0.842            3669              417              691   \n",
       "1         0.840            3661              425              699   \n",
       "2         0.842            3669              417              691   \n",
       "\n",
       "   True negatives  \n",
       "0           25223  \n",
       "1           25215  \n",
       "2           25223  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"### Results of random forest classification on train dataset:\"))\n",
    "display(train_table_ran)\n",
    "\n",
    "display(Markdown(\"### Results of random forest classification on test dataset:\"))\n",
    "display(test_table_ran)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62afe63-c774-4b5b-ace0-d90eda6601ef",
   "metadata": {},
   "source": [
    "In this case, there might be a slight overfitting, but the results are very good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa14e8-4770-4c18-9cbc-38f7a6a92739",
   "metadata": {},
   "source": [
    "\n",
    "## Boosting\n",
    "\n",
    "This time, we'll cross validate on the learning rate and the depths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e0729d8-b3fa-471d-8683-4a6bd20b57f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a318056f2ab4e46aacbf1a3c43e452a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348f25fce32c451a9cf7162f59775027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c594424682a8481bb502e18f5a1d50c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834d0737a36e4884bf9ed251a35833fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc5d9d7b23c4e529e8c09b1836d97e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc846b64dbf475b9b4a7a15b227d8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbf3fb176734022bf1e234dbb728e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722232c2581d4d2bbef482b9c2a66d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_splits = 5\n",
    "\n",
    "lr_range = np.array([0.005, 0.01, 0.05, 0.1, 0.5, 1, 1.5])\n",
    "depths_range = np.arange(3, 6, dtype = int)\n",
    "# I'm considering only between 3 and 5 because, before, all the trees went to max_depth = 3, and because I'm afraid it\n",
    "# would go in overfitting regime for max_depth > 5.\n",
    "\n",
    "accuracy_cv_matrix = np.empty((len(lr_range), len(depths_range)))\n",
    "precision_cv_matrix = np.empty((len(lr_range), len(depths_range)))\n",
    "completeness_cv_matrix = np.empty((len(lr_range), len(depths_range)))\n",
    "\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=336)\n",
    "\n",
    "for i, l_rate in tqdm(enumerate(lr_range), total = len(lr_range)):\n",
    "\n",
    "    for j, depth in tqdm(enumerate(depths_range), total = len(depths_range)):\n",
    "    \n",
    "        boost = GradientBoostingClassifier(learning_rate = l_rate, max_depth = depth, random_state = 336)\n",
    "        \n",
    "        accuracy = []\n",
    "        precision = []\n",
    "        completeness = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(X_train):\n",
    "            X_train_cv, X_test_cv = X_train[train_index], X_train[test_index]\n",
    "            y_train_cv, y_test_cv = y_train[train_index], y_train[test_index]\n",
    "            \n",
    "            boost.fit(X_train_cv, y_train_cv)\n",
    "            y_pred_test_cv = boost.predict(X_test_cv)\n",
    "            \n",
    "            accuracy.append(accuracy_score(y_test_cv, y_pred_test_cv))\n",
    "            precision.append(precision_score(y_test_cv, y_pred_test_cv, zero_division=0))\n",
    "            completeness.append(recall_score(y_test_cv, y_pred_test_cv))\n",
    "    \n",
    "        accuracy_cv_matrix[i, j] = np.mean(accuracy)\n",
    "        precision_cv_matrix[i, j] = np.mean(precision)\n",
    "        completeness_cv_matrix[i, j] = np.mean(completeness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ff46605-9c0e-4c39-9f59-611c0a6adb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85682857, 0.85682857, 0.85682857],\n",
       "       [0.93645714, 0.94688571, 0.9514    ],\n",
       "       [0.96067143, 0.96444286, 0.96601429],\n",
       "       [0.96592857, 0.9694    , 0.97152857],\n",
       "       [0.97574286, 0.97614286, 0.9746    ],\n",
       "       [0.97415714, 0.97044286, 0.97108571],\n",
       "       [0.90108571, 0.87495714, 0.92047143]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23801600-6536-4573-b310-df77eed87d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        ],\n",
       "       [0.93003771, 0.92970925, 0.93755431],\n",
       "       [0.89645333, 0.90098612, 0.90103652],\n",
       "       [0.90330504, 0.90995239, 0.91684442],\n",
       "       [0.92443941, 0.92588403, 0.92048307],\n",
       "       [0.91482023, 0.90535584, 0.90336663],\n",
       "       [0.67928091, 0.61301356, 0.77009261]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a6c3638-e476-4d0d-8678-40338cb47dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        ],\n",
       "       [0.60141549, 0.68061559, 0.70778781],\n",
       "       [0.82014717, 0.84465577, 0.85697767],\n",
       "       [0.85358394, 0.87285032, 0.88132345],\n",
       "       [0.90449495, 0.9059227 , 0.90053948],\n",
       "       [0.90378202, 0.88666058, 0.89368202],\n",
       "       [0.81122092, 0.67677628, 0.62347459]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad3862d4-1b05-417f-8daf-85d443ccd6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rates considered:\n",
      "[0.005 0.01  0.05  0.1   0.5   1.    1.5  ]\n",
      "depths considered:\n",
      "[3 4 5]\n",
      "\n",
      "Scoring metric: Accuracy\n",
      " Best learning rate: 0.50\n",
      " Best max_depth: 4\n",
      "\n",
      "Scoring metric: Contamination\n",
      " Best learning rate: 0.01\n",
      " Best max_depth: 5\n",
      "\n",
      "Scoring metric: Completeness\n",
      " Best learning rate: 0.50\n",
      " Best max_depth: 4\n"
     ]
    }
   ],
   "source": [
    "print('Learning rates considered:')\n",
    "print(lr_range)\n",
    "\n",
    "print('depths considered:')\n",
    "print(depths_range)\n",
    "\n",
    "cv_matrices = [accuracy_cv_matrix, precision_cv_matrix, completeness_cv_matrix]\n",
    "\n",
    "best_lr_boo2 = np.empty(3)\n",
    "best_depth_boo2 = np.empty(3)\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    best_index_flat = np.argmax(cv_matrices[i]) \n",
    "    best_index_2d = np.unravel_index(best_index_flat, cv_matrices[i].shape)\n",
    "    \n",
    "    best_lr_boo2[i] = lr_range[best_index_2d[0]]\n",
    "    best_depth_boo2[i] = depths_range[best_index_2d[1]]\n",
    "    \n",
    "    print('\\nScoring metric: ' + str(scoring_metrics[i]))\n",
    "    print(' Best learning rate: %.2f' % best_lr_boo2[i]) \n",
    "    print(' Best max_depth: %i' % best_depth_boo2[i]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22c4a2ae-18a8-4833-8c7c-dcefeac582cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd4734a2758494697c7c83fd30a0c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies_train_boo2 = np.empty(3)\n",
    "contaminations_train_boo2 = np.empty(3)\n",
    "completenesses_train_boo2 = np.empty(3)\n",
    "tp_train_boo2 = np.empty(3)\n",
    "fp_train_boo2 = np.empty(3)\n",
    "fn_train_boo2 = np.empty(3)\n",
    "tn_train_boo2 = np.empty(3)\n",
    "\n",
    "accuracies_test_boo2 = np.empty(3)\n",
    "contaminations_test_boo2 = np.empty(3)\n",
    "completenesses_test_boo2 = np.empty(3)\n",
    "tp_test_boo2 = np.empty(3)\n",
    "fp_test_boo2 = np.empty(3)\n",
    "fn_test_boo2 = np.empty(3)\n",
    "tn_test_boo2 = np.empty(3)\n",
    "\n",
    "for (i, l_rate), depth in tqdm(zip(enumerate(best_lr_boo2), best_depth_boo2), total=len(best_lr_boo2)):\n",
    "\n",
    "    boost = GradientBoostingClassifier(learning_rate = l_rate, max_depth = int(depth), random_state = 336)\n",
    "    boost.fit(X_train, y_train)\n",
    "    y_train_pred = boost.predict(X_train)\n",
    "    y_test_pred = boost.predict(X_test)\n",
    "\n",
    "    accuracies_train_boo2[i] = accuracy_score(y_train, y_train_pred)\n",
    "    contaminations_train_boo2[i] = 1 - precision_score(y_train, y_train_pred)\n",
    "    completenesses_train_boo2[i] = recall_score(y_train, y_train_pred)\n",
    "    conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "    tn_train_boo2[i], fp_train_boo2[i], fn_train_boo2[i], tp_train_boo2[i] = conf_matrix_train.ravel()\n",
    "    \n",
    "    accuracies_test_boo2[i] = accuracy_score(y_test, y_test_pred)\n",
    "    contaminations_test_boo2[i] = 1 - precision_score(y_test, y_test_pred)\n",
    "    completenesses_test_boo2[i] = recall_score(y_test, y_test_pred)\n",
    "    conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "    tn_test_boo2[i], fp_test_boo2[i], fn_test_boo2[i], tp_test_boo2[i] = conf_matrix_test.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71bd1163-4910-4112-b88c-840ede987b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table_boo2 = pd.DataFrame({\n",
    "    'Scoring metric for CV': scoring_metrics,\n",
    "    'Learning_rate': best_lr_boo2,\n",
    "    'Max_depth': best_depth_boo2,\n",
    "    'Accuracy': accuracies_train_boo2,\n",
    "    'Contamination': contaminations_train_boo2,\n",
    "    'Completeness': completenesses_train_boo2,\n",
    "    'True positives': tp_train_boo2,\n",
    "    'False positives': fp_train_boo2,\n",
    "    'False negatives': fn_train_boo2,\n",
    "    'True negatives': tn_train_boo2\n",
    "})\n",
    "\n",
    "train_table_boo2[['Learning_rate', 'Accuracy', 'Contamination', 'Completeness']] = train_table_boo2[['Learning_rate', 'Accuracy', 'Contamination', 'Completeness']].round(3)\n",
    "train_table_boo2[['Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']] = train_table_boo2[['Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "test_table_boo2 = pd.DataFrame({\n",
    "    'Scoring metric for CV': scoring_metrics,\n",
    "    'Learning_rate': best_lr_boo2,\n",
    "    'Max_depth': best_depth_boo2,\n",
    "    'Accuracy': accuracies_test_boo2,\n",
    "    'Contamination': contaminations_test_boo2,\n",
    "    'Completeness': completenesses_test_boo2,\n",
    "    'True positives': tp_test_boo2,\n",
    "    'False positives': fp_test_boo2,\n",
    "    'False negatives': fn_test_boo2,\n",
    "    'True negatives': tn_test_boo2\n",
    "    })\n",
    "\n",
    "test_table_boo2[['Learning_rate', 'Accuracy', 'Contamination', 'Completeness']] = test_table_boo2[['Learning_rate', 'Accuracy', 'Contamination', 'Completeness']].round(3)\n",
    "test_table_boo2[['Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']] = test_table_boo2[['Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53cc2454-e3ff-485f-be9b-639aefc12c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Results of boosting classification on train dataset:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scoring metric for CV</th>\n",
       "      <th>Learning_rate</th>\n",
       "      <th>Max_depth</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>True positives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "      <th>True negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.96</td>\n",
       "      <td>9620</td>\n",
       "      <td>338</td>\n",
       "      <td>402</td>\n",
       "      <td>59640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contamination</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.72</td>\n",
       "      <td>7212</td>\n",
       "      <td>448</td>\n",
       "      <td>2810</td>\n",
       "      <td>59530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Completeness</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.96</td>\n",
       "      <td>9620</td>\n",
       "      <td>338</td>\n",
       "      <td>402</td>\n",
       "      <td>59640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scoring metric for CV  Learning_rate  Max_depth  Accuracy  Contamination  \\\n",
       "0              Accuracy           0.50          4     0.989          0.034   \n",
       "1         Contamination           0.01          5     0.953          0.058   \n",
       "2          Completeness           0.50          4     0.989          0.034   \n",
       "\n",
       "   Completeness  True positives  False positives  False negatives  \\\n",
       "0          0.96            9620              338              402   \n",
       "1          0.72            7212              448             2810   \n",
       "2          0.96            9620              338              402   \n",
       "\n",
       "   True negatives  \n",
       "0           59640  \n",
       "1           59530  \n",
       "2           59640  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Results of boosting classification on test dataset:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scoring metric for CV</th>\n",
       "      <th>Learning_rate</th>\n",
       "      <th>Max_depth</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>True positives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "      <th>True negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.901</td>\n",
       "      <td>3930</td>\n",
       "      <td>351</td>\n",
       "      <td>430</td>\n",
       "      <td>25289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contamination</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.713</td>\n",
       "      <td>3108</td>\n",
       "      <td>236</td>\n",
       "      <td>1252</td>\n",
       "      <td>25404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Completeness</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.901</td>\n",
       "      <td>3930</td>\n",
       "      <td>351</td>\n",
       "      <td>430</td>\n",
       "      <td>25289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scoring metric for CV  Learning_rate  Max_depth  Accuracy  Contamination  \\\n",
       "0              Accuracy           0.50          4     0.974          0.082   \n",
       "1         Contamination           0.01          5     0.950          0.071   \n",
       "2          Completeness           0.50          4     0.974          0.082   \n",
       "\n",
       "   Completeness  True positives  False positives  False negatives  \\\n",
       "0         0.901            3930              351              430   \n",
       "1         0.713            3108              236             1252   \n",
       "2         0.901            3930              351              430   \n",
       "\n",
       "   True negatives  \n",
       "0           25289  \n",
       "1           25404  \n",
       "2           25289  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"### Results of boosting classification on train dataset:\"))\n",
    "display(train_table_boo2)\n",
    "\n",
    "display(Markdown(\"### Results of boosting classification on test dataset:\"))\n",
    "display(test_table_boo2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ee2a67-2c51-4396-b842-cb44c3c6db5c",
   "metadata": {},
   "source": [
    "\n",
    "## Comparison of the results until now\n",
    "\n",
    "Let's display the test results for the classifiers to see which one is the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96649e4e-5189-4d9c-9f7e-9124ba26aa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Simple decision tree:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scoring metric for CV</th>\n",
       "      <th>Max_depth</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>True positives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "      <th>True negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>8</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.853</td>\n",
       "      <td>3719</td>\n",
       "      <td>635</td>\n",
       "      <td>641</td>\n",
       "      <td>25005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contamination</td>\n",
       "      <td>2</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.788</td>\n",
       "      <td>3435</td>\n",
       "      <td>1036</td>\n",
       "      <td>925</td>\n",
       "      <td>24604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Completeness</td>\n",
       "      <td>1</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.788</td>\n",
       "      <td>3435</td>\n",
       "      <td>1036</td>\n",
       "      <td>925</td>\n",
       "      <td>24604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scoring metric for CV  Max_depth  Accuracy  Contamination  Completeness  \\\n",
       "0              Accuracy          8     0.957          0.146         0.853   \n",
       "1         Contamination          2     0.935          0.232         0.788   \n",
       "2          Completeness          1     0.935          0.232         0.788   \n",
       "\n",
       "   True positives  False positives  False negatives  True negatives  \n",
       "0            3719              635              641           25005  \n",
       "1            3435             1036              925           24604  \n",
       "2            3435             1036              925           24604  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Bagged decision tree:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scoring metric for CV</th>\n",
       "      <th>Number of trees</th>\n",
       "      <th>Max_depth</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>True positives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "      <th>True negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.852</td>\n",
       "      <td>3714</td>\n",
       "      <td>492</td>\n",
       "      <td>646</td>\n",
       "      <td>25148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contamination</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.607</td>\n",
       "      <td>2646</td>\n",
       "      <td>301</td>\n",
       "      <td>1714</td>\n",
       "      <td>25339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Completeness</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.869</td>\n",
       "      <td>3789</td>\n",
       "      <td>1813</td>\n",
       "      <td>571</td>\n",
       "      <td>23827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scoring metric for CV  Number of trees  Max_depth  Accuracy  Contamination  \\\n",
       "0              Accuracy               15         10     0.962          0.117   \n",
       "1         Contamination               15          2     0.933          0.102   \n",
       "2          Completeness               10          1     0.921          0.324   \n",
       "\n",
       "   Completeness  True positives  False positives  False negatives  \\\n",
       "0         0.852            3714              492              646   \n",
       "1         0.607            2646              301             1714   \n",
       "2         0.869            3789             1813              571   \n",
       "\n",
       "   True negatives  \n",
       "0           25148  \n",
       "1           25339  \n",
       "2           23827  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Random forest:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scoring metric for CV</th>\n",
       "      <th>Number of trees</th>\n",
       "      <th>Max_depth</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>True positives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "      <th>True negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>200</td>\n",
       "      <td>13</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.842</td>\n",
       "      <td>3669</td>\n",
       "      <td>417</td>\n",
       "      <td>691</td>\n",
       "      <td>25223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contamination</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.840</td>\n",
       "      <td>3661</td>\n",
       "      <td>425</td>\n",
       "      <td>699</td>\n",
       "      <td>25215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Completeness</td>\n",
       "      <td>200</td>\n",
       "      <td>13</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.842</td>\n",
       "      <td>3669</td>\n",
       "      <td>417</td>\n",
       "      <td>691</td>\n",
       "      <td>25223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scoring metric for CV  Number of trees  Max_depth  Accuracy  Contamination  \\\n",
       "0              Accuracy              200         13     0.963          0.102   \n",
       "1         Contamination               50         13     0.963          0.104   \n",
       "2          Completeness              200         13     0.963          0.102   \n",
       "\n",
       "   Completeness  True positives  False positives  False negatives  \\\n",
       "0         0.842            3669              417              691   \n",
       "1         0.840            3661              425              699   \n",
       "2         0.842            3669              417              691   \n",
       "\n",
       "   True negatives  \n",
       "0           25223  \n",
       "1           25215  \n",
       "2           25223  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Boosting:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scoring metric for CV</th>\n",
       "      <th>Learning_rate</th>\n",
       "      <th>Max_depth</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>True positives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "      <th>True negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.901</td>\n",
       "      <td>3930</td>\n",
       "      <td>351</td>\n",
       "      <td>430</td>\n",
       "      <td>25289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contamination</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.713</td>\n",
       "      <td>3108</td>\n",
       "      <td>236</td>\n",
       "      <td>1252</td>\n",
       "      <td>25404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Completeness</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.901</td>\n",
       "      <td>3930</td>\n",
       "      <td>351</td>\n",
       "      <td>430</td>\n",
       "      <td>25289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scoring metric for CV  Learning_rate  Max_depth  Accuracy  Contamination  \\\n",
       "0              Accuracy           0.50          4     0.974          0.082   \n",
       "1         Contamination           0.01          5     0.950          0.071   \n",
       "2          Completeness           0.50          4     0.974          0.082   \n",
       "\n",
       "   Completeness  True positives  False positives  False negatives  \\\n",
       "0         0.901            3930              351              430   \n",
       "1         0.713            3108              236             1252   \n",
       "2         0.901            3930              351              430   \n",
       "\n",
       "   True negatives  \n",
       "0           25289  \n",
       "1           25404  \n",
       "2           25289  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"#### Simple decision tree:\"))\n",
    "display(test_table_dtc)\n",
    "\n",
    "display(Markdown(\"#### Bagged decision tree:\"))\n",
    "display(test_table_bag)\n",
    "\n",
    "display(Markdown(\"#### Random forest:\"))\n",
    "display(test_table_ran)\n",
    "\n",
    "display(Markdown(\"#### Boosting:\"))\n",
    "display(test_table_boo2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c7ad9-2818-4449-9cf7-ee95677b701c",
   "metadata": {},
   "source": [
    "The best classifier, for now, is the boosting one. Let's try to get an even better result on it with PCA.\n",
    "\n",
    "## PCA\n",
    "\n",
    "We can try performing a PCA before boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18b4bc46-0834-4eca-b382-74f71dd673a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e999121ba84c8b9ae7faa5b33c4707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "ndim = np.arange(1, 14)\n",
    "\n",
    "accuracies_train_pca = np.empty(len(ndim))\n",
    "contaminations_train_pca = np.empty(len(ndim))\n",
    "completenesses_train_pca = np.empty(len(ndim))\n",
    "tp_train_pca = np.empty(len(ndim))\n",
    "fp_train_pca = np.empty(len(ndim))\n",
    "fn_train_pca = np.empty(len(ndim))\n",
    "tn_train_pca = np.empty(len(ndim))\n",
    "\n",
    "accuracies_test_pca = np.empty(len(ndim))\n",
    "contaminations_test_pca = np.empty(len(ndim))\n",
    "completenesses_test_pca = np.empty(len(ndim))\n",
    "tp_test_pca = np.empty(len(ndim))\n",
    "fp_test_pca = np.empty(len(ndim))\n",
    "fn_test_pca = np.empty(len(ndim))\n",
    "tn_test_pca = np.empty(len(ndim))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=336)\n",
    "\n",
    "for i, n in tqdm(enumerate(ndim), total=len(ndim)):\n",
    "\n",
    "    pca = PCA(n_components=n, random_state = 336)\n",
    "\n",
    "    # Dividing the fit_transform so that the test and train sets remain separated. So, I'm fitting the pca only on the train set, \n",
    "    # and then using it to transform both train and test set.\n",
    "    X_train_tr = pca.fit_transform(X_train)\n",
    "    X_test_tr = pca.transform(X_test)\n",
    "        \n",
    "    boost_pca = GradientBoostingClassifier(learning_rate = 0.50, max_depth = 4, random_state = 336)\n",
    "    boost_pca.fit(X_train_tr, y_train)\n",
    "    y_train_pred = boost_pca.predict(X_train_tr)\n",
    "    y_test_pred = boost_pca.predict(X_test_tr)\n",
    "\n",
    "    accuracies_train_pca[i] = accuracy_score(y_train, y_train_pred)\n",
    "    contaminations_train_pca[i] = 1 - precision_score(y_train, y_train_pred, zero_division=0)\n",
    "    completenesses_train_pca[i] = recall_score(y_train, y_train_pred)\n",
    "    conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "    tn_train_pca[i], fp_train_pca[i], fn_train_pca[i], tp_train_pca[i] = conf_matrix_train.ravel()\n",
    "    \n",
    "    accuracies_test_pca[i] = accuracy_score(y_test, y_test_pred)\n",
    "    contaminations_test_pca[i] = 1 - precision_score(y_test, y_test_pred, zero_division=0)\n",
    "    completenesses_test_pca[i] = recall_score(y_test, y_test_pred)\n",
    "    conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "    tn_test_pca[i], fp_test_pca[i], fn_test_pca[i], tp_test_pca[i] = conf_matrix_test.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2aff6e2f-9aea-418d-b713-61df1490663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table_pca = pd.DataFrame({\n",
    "    'PCA Dimensions': ndim,\n",
    "    'Accuracy': accuracies_train_pca,\n",
    "    'Contamination': contaminations_train_pca,\n",
    "    'Completeness': completenesses_train_pca,\n",
    "    'TP': tp_train_pca,\n",
    "    'FP': fp_train_pca,\n",
    "    'FN': fn_train_pca,\n",
    "    'TN': tn_train_pca\n",
    "})\n",
    "\n",
    "train_table_pca[['Accuracy', 'Contamination', 'Completeness']] = train_table_pca[['Accuracy', 'Contamination', 'Completeness']].round(3)\n",
    "train_table_pca[['TP', 'FP', 'FN', 'TN']] = train_table_pca[['TP', 'FP', 'FN', 'TN']].astype(int)\n",
    "\n",
    "# Create DataFrame for test metrics\n",
    "test_table_pca = pd.DataFrame({\n",
    "    'PCA Dimensions': ndim,\n",
    "    'Accuracy': accuracies_test_pca,\n",
    "    'Contamination': contaminations_test_pca,\n",
    "    'Completeness': completenesses_test_pca,\n",
    "    'TP': tp_test_pca,\n",
    "    'FP': fp_test_pca,\n",
    "    'FN': fn_test_pca,\n",
    "    'TN': tn_test_pca\n",
    "})\n",
    "\n",
    "test_table_pca[['Accuracy', 'Contamination', 'Completeness']] = test_table_pca[['Accuracy', 'Contamination', 'Completeness']].round(3)\n",
    "test_table_pca[['TP', 'FP', 'FN', 'TN']] = test_table_pca[['TP', 'FP', 'FN', 'TN']].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08021aca-97be-47a3-8d1b-b732ef034d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Results of PCA before boosting on train dataset:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA Dimensions</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.059</td>\n",
       "      <td>590</td>\n",
       "      <td>63</td>\n",
       "      <td>9432</td>\n",
       "      <td>59915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.061</td>\n",
       "      <td>609</td>\n",
       "      <td>54</td>\n",
       "      <td>9413</td>\n",
       "      <td>59924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.839</td>\n",
       "      <td>8413</td>\n",
       "      <td>1006</td>\n",
       "      <td>1609</td>\n",
       "      <td>58972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.839</td>\n",
       "      <td>8409</td>\n",
       "      <td>993</td>\n",
       "      <td>1613</td>\n",
       "      <td>58985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.889</td>\n",
       "      <td>8907</td>\n",
       "      <td>871</td>\n",
       "      <td>1115</td>\n",
       "      <td>59107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.908</td>\n",
       "      <td>9095</td>\n",
       "      <td>708</td>\n",
       "      <td>927</td>\n",
       "      <td>59270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.913</td>\n",
       "      <td>9151</td>\n",
       "      <td>671</td>\n",
       "      <td>871</td>\n",
       "      <td>59307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.906</td>\n",
       "      <td>9076</td>\n",
       "      <td>729</td>\n",
       "      <td>946</td>\n",
       "      <td>59249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.914</td>\n",
       "      <td>9161</td>\n",
       "      <td>710</td>\n",
       "      <td>861</td>\n",
       "      <td>59268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.903</td>\n",
       "      <td>9052</td>\n",
       "      <td>814</td>\n",
       "      <td>970</td>\n",
       "      <td>59164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.913</td>\n",
       "      <td>9154</td>\n",
       "      <td>696</td>\n",
       "      <td>868</td>\n",
       "      <td>59282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.913</td>\n",
       "      <td>9154</td>\n",
       "      <td>704</td>\n",
       "      <td>868</td>\n",
       "      <td>59274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.955</td>\n",
       "      <td>9567</td>\n",
       "      <td>313</td>\n",
       "      <td>455</td>\n",
       "      <td>59665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PCA Dimensions  Accuracy  Contamination  Completeness    TP    FP    FN  \\\n",
       "0                1     0.864          0.096         0.059   590    63  9432   \n",
       "1                2     0.865          0.081         0.061   609    54  9413   \n",
       "2                3     0.963          0.107         0.839  8413  1006  1609   \n",
       "3                4     0.963          0.106         0.839  8409   993  1613   \n",
       "4                5     0.972          0.089         0.889  8907   871  1115   \n",
       "5                6     0.977          0.072         0.908  9095   708   927   \n",
       "6                7     0.978          0.068         0.913  9151   671   871   \n",
       "7                8     0.976          0.074         0.906  9076   729   946   \n",
       "8                9     0.978          0.072         0.914  9161   710   861   \n",
       "9               10     0.975          0.083         0.903  9052   814   970   \n",
       "10              11     0.978          0.071         0.913  9154   696   868   \n",
       "11              12     0.978          0.071         0.913  9154   704   868   \n",
       "12              13     0.989          0.032         0.955  9567   313   455   \n",
       "\n",
       "       TN  \n",
       "0   59915  \n",
       "1   59924  \n",
       "2   58972  \n",
       "3   58985  \n",
       "4   59107  \n",
       "5   59270  \n",
       "6   59307  \n",
       "7   59249  \n",
       "8   59268  \n",
       "9   59164  \n",
       "10  59282  \n",
       "11  59274  \n",
       "12  59665  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Results of PCA before boosting on test dataset:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA Dimensions</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.008</td>\n",
       "      <td>34</td>\n",
       "      <td>266</td>\n",
       "      <td>4326</td>\n",
       "      <td>25374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.010</td>\n",
       "      <td>42</td>\n",
       "      <td>225</td>\n",
       "      <td>4318</td>\n",
       "      <td>25415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.780</td>\n",
       "      <td>3402</td>\n",
       "      <td>718</td>\n",
       "      <td>958</td>\n",
       "      <td>24922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.777</td>\n",
       "      <td>3389</td>\n",
       "      <td>716</td>\n",
       "      <td>971</td>\n",
       "      <td>24924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.829</td>\n",
       "      <td>3613</td>\n",
       "      <td>673</td>\n",
       "      <td>747</td>\n",
       "      <td>24967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.855</td>\n",
       "      <td>3729</td>\n",
       "      <td>525</td>\n",
       "      <td>631</td>\n",
       "      <td>25115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.857</td>\n",
       "      <td>3737</td>\n",
       "      <td>537</td>\n",
       "      <td>623</td>\n",
       "      <td>25103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.852</td>\n",
       "      <td>3714</td>\n",
       "      <td>524</td>\n",
       "      <td>646</td>\n",
       "      <td>25116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.853</td>\n",
       "      <td>3719</td>\n",
       "      <td>533</td>\n",
       "      <td>641</td>\n",
       "      <td>25107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.853</td>\n",
       "      <td>3717</td>\n",
       "      <td>533</td>\n",
       "      <td>643</td>\n",
       "      <td>25107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.850</td>\n",
       "      <td>3705</td>\n",
       "      <td>534</td>\n",
       "      <td>655</td>\n",
       "      <td>25106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.863</td>\n",
       "      <td>3761</td>\n",
       "      <td>471</td>\n",
       "      <td>599</td>\n",
       "      <td>25169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.898</td>\n",
       "      <td>3917</td>\n",
       "      <td>359</td>\n",
       "      <td>443</td>\n",
       "      <td>25281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PCA Dimensions  Accuracy  Contamination  Completeness    TP   FP    FN  \\\n",
       "0                1     0.847          0.887         0.008    34  266  4326   \n",
       "1                2     0.849          0.843         0.010    42  225  4318   \n",
       "2                3     0.944          0.174         0.780  3402  718   958   \n",
       "3                4     0.944          0.174         0.777  3389  716   971   \n",
       "4                5     0.953          0.157         0.829  3613  673   747   \n",
       "5                6     0.961          0.123         0.855  3729  525   631   \n",
       "6                7     0.961          0.126         0.857  3737  537   623   \n",
       "7                8     0.961          0.124         0.852  3714  524   646   \n",
       "8                9     0.961          0.125         0.853  3719  533   641   \n",
       "9               10     0.961          0.125         0.853  3717  533   643   \n",
       "10              11     0.960          0.126         0.850  3705  534   655   \n",
       "11              12     0.964          0.111         0.863  3761  471   599   \n",
       "12              13     0.973          0.084         0.898  3917  359   443   \n",
       "\n",
       "       TN  \n",
       "0   25374  \n",
       "1   25415  \n",
       "2   24922  \n",
       "3   24924  \n",
       "4   24967  \n",
       "5   25115  \n",
       "6   25103  \n",
       "7   25116  \n",
       "8   25107  \n",
       "9   25107  \n",
       "10  25106  \n",
       "11  25169  \n",
       "12  25281  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"### Results of PCA before boosting on train dataset:\"))\n",
    "display(train_table_pca)\n",
    "\n",
    "display(Markdown(\"### Results of PCA before boosting on test dataset:\"))\n",
    "display(test_table_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d9b24d-7f11-4455-80dc-3e091dd3ac56",
   "metadata": {},
   "source": [
    "The results seem to get better as the number of dimensions increases, with the best results for ndim = 13. Let's cross-validate, as before, on the learning rate and the maximum depth, working with ndim = 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ff76ab3-693b-4ecc-85b2-26b463eb3abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6d89f77a0b4a6ab6c86d0f4fe0a03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a46d8e2faa462eb9bfee7007b5682c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a320bf255354064b9559a9bfd926c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2068bc9081bf4fc7b5b0ca4b9c683596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bc00ba1ae945699112e1042a035364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e7ec8907a44d70b9ee641a0bcb863b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7215515bfcbf429ba1d1f3fac265f619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8610ce875b7d4aee85e144df9514eda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_splits = 5\n",
    "\n",
    "lr_range = np.array([0.005, 0.01, 0.05, 0.1, 0.5, 1, 1.5])\n",
    "depths_range = np.arange(3, 6, dtype = int)\n",
    "# I'm considering only between 3 and 5 because, before, all the trees went to max_depth = 3, and because I'm afraid it\n",
    "# would go in overfitting regime for max_depth > 5.\n",
    "\n",
    "accuracy_cv_matrix = np.empty((len(lr_range), len(depths_range)))\n",
    "precision_cv_matrix = np.empty((len(lr_range), len(depths_range)))\n",
    "completeness_cv_matrix = np.empty((len(lr_range), len(depths_range)))\n",
    "\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=336)\n",
    "\n",
    "pca = PCA(n_components=13, random_state = 336)\n",
    "\n",
    "# Dividing the fit_transform so that the test and train sets remain separated. So, I'm fitting the pca only on the train set, \n",
    "# and then using it to transform both train and test set.\n",
    "X_train_tr = pca.fit_transform(X_train)\n",
    "X_test_tr = pca.transform(X_test)\n",
    "\n",
    "for i, l_rate in tqdm(enumerate(lr_range), total = len(lr_range)):\n",
    "\n",
    "    for j, depth in tqdm(enumerate(depths_range), total = len(depths_range)):\n",
    "    \n",
    "        boost = GradientBoostingClassifier(learning_rate = l_rate, max_depth = depth, random_state = 336)\n",
    "        \n",
    "        accuracy = []\n",
    "        precision = []\n",
    "        completeness = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(X_train_tr):\n",
    "            X_train_cv, X_test_cv = X_train_tr[train_index], X_train_tr[test_index]\n",
    "            y_train_cv, y_test_cv = y_train[train_index], y_train[test_index]\n",
    "            \n",
    "            boost.fit(X_train_cv, y_train_cv)\n",
    "            y_pred_test_cv = boost.predict(X_test_cv)\n",
    "            \n",
    "            accuracy.append(accuracy_score(y_test_cv, y_pred_test_cv))\n",
    "            precision.append(precision_score(y_test_cv, y_pred_test_cv, zero_division=0))\n",
    "            completeness.append(recall_score(y_test_cv, y_pred_test_cv))\n",
    "    \n",
    "        accuracy_cv_matrix[i, j] = np.mean(accuracy)\n",
    "        precision_cv_matrix[i, j] = np.mean(precision)\n",
    "        completeness_cv_matrix[i, j] = np.mean(completeness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bed9d9f2-2944-42c9-9537-62c5fb5cf440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85682857, 0.85682857, 0.85682857],\n",
       "       [0.93628571, 0.946     , 0.9495    ],\n",
       "       [0.95935714, 0.96261429, 0.96427143],\n",
       "       [0.96425714, 0.96747143, 0.96945714],\n",
       "       [0.97354286, 0.97347143, 0.97311429],\n",
       "       [0.96921429, 0.9701    , 0.96852857],\n",
       "       [0.96675714, 0.93777143, 0.91877143]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cb02120-5165-4371-a650-078c3557eae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        ],\n",
       "       [0.92669115, 0.92721467, 0.9334948 ],\n",
       "       [0.89171922, 0.89430856, 0.89432117],\n",
       "       [0.89817382, 0.90497724, 0.90957215],\n",
       "       [0.92001704, 0.91613604, 0.91551451],\n",
       "       [0.89559118, 0.8998518 , 0.8975253 ],\n",
       "       [0.88963085, 0.80770672, 0.7497208 ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b836ae87-0b8a-4a4b-835e-31f2ddd0123a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        ],\n",
       "       [0.60267132, 0.67600333, 0.69712257],\n",
       "       [0.81520173, 0.83801033, 0.8511757 ],\n",
       "       [0.84642439, 0.86359476, 0.87369008],\n",
       "       [0.8930146 , 0.89698617, 0.89491624],\n",
       "       [0.88877949, 0.89048362, 0.88104877],\n",
       "       [0.87674904, 0.7403713 , 0.64010869]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc2978a7-6108-4bac-bd0d-6e6febdeaac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rates considered:\n",
      "[0.005 0.01  0.05  0.1   0.5   1.    1.5  ]\n",
      "depths considered:\n",
      "[3 4 5]\n",
      "\n",
      "Scoring metric: Accuracy\n",
      " Best learning rate: 0.50\n",
      " Best max_depth: 3\n",
      "\n",
      "Scoring metric: Contamination\n",
      " Best learning rate: 0.01\n",
      " Best max_depth: 5\n",
      "\n",
      "Scoring metric: Completeness\n",
      " Best learning rate: 0.50\n",
      " Best max_depth: 4\n"
     ]
    }
   ],
   "source": [
    "print('Learning rates considered:')\n",
    "print(lr_range)\n",
    "\n",
    "print('depths considered:')\n",
    "print(depths_range)\n",
    "\n",
    "cv_matrices = [accuracy_cv_matrix, precision_cv_matrix, completeness_cv_matrix]\n",
    "\n",
    "best_lr_pca_cv = np.empty(3)\n",
    "best_depth_pca_cv = np.empty(3)\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    best_index_flat = np.argmax(cv_matrices[i]) \n",
    "    best_index_2d = np.unravel_index(best_index_flat, cv_matrices[i].shape)\n",
    "    \n",
    "    best_lr_pca_cv[i] = lr_range[best_index_2d[0]]\n",
    "    best_depth_pca_cv[i] = depths_range[best_index_2d[1]]\n",
    "    \n",
    "    print('\\nScoring metric: ' + str(scoring_metrics[i]))\n",
    "    print(' Best learning rate: %.2f' % best_lr_pca_cv[i]) \n",
    "    print(' Best max_depth: %i' % best_depth_pca_cv[i]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33e0651b-291d-4a66-8ab3-46156050e0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f245413d7fac41fe9c8a08d25ca24843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies_train_pca_cv = np.empty(3)\n",
    "contaminations_train_pca_cv = np.empty(3)\n",
    "completenesses_train_pca_cv = np.empty(3)\n",
    "tp_train_pca_cv = np.empty(3)\n",
    "fp_train_pca_cv = np.empty(3)\n",
    "fn_train_pca_cv = np.empty(3)\n",
    "tn_train_pca_cv = np.empty(3)\n",
    "\n",
    "accuracies_test_pca_cv = np.empty(3)\n",
    "contaminations_test_pca_cv = np.empty(3)\n",
    "completenesses_test_pca_cv = np.empty(3)\n",
    "tp_test_pca_cv = np.empty(3)\n",
    "fp_test_pca_cv = np.empty(3)\n",
    "fn_test_pca_cv = np.empty(3)\n",
    "tn_test_pca_cv = np.empty(3)\n",
    "\n",
    "for (i, l_rate), depth in tqdm(zip(enumerate(best_lr_pca_cv), best_depth_pca_cv), total=len(best_lr_pca_cv)):\n",
    "\n",
    "    boost_pca_cv = GradientBoostingClassifier(learning_rate = l_rate, max_depth = int(depth), random_state = 336)\n",
    "    boost_pca_cv.fit(X_train_tr, y_train)\n",
    "    y_train_pred = boost_pca_cv.predict(X_train_tr)\n",
    "    y_test_pred = boost_pca_cv.predict(X_test_tr)\n",
    "\n",
    "    accuracies_train_pca_cv[i] = accuracy_score(y_train, y_train_pred)\n",
    "    contaminations_train_pca_cv[i] = 1 - precision_score(y_train, y_train_pred)\n",
    "    completenesses_train_pca_cv[i] = recall_score(y_train, y_train_pred)\n",
    "    conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "    tn_train_pca_cv[i], fp_train_pca_cv[i], fn_train_pca_cv[i], tp_train_pca_cv[i] = conf_matrix_train.ravel()\n",
    "    \n",
    "    accuracies_test_pca_cv[i] = accuracy_score(y_test, y_test_pred)\n",
    "    contaminations_test_pca_cv[i] = 1 - precision_score(y_test, y_test_pred)\n",
    "    completenesses_test_pca_cv[i] = recall_score(y_test, y_test_pred)\n",
    "    conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "    tn_test_pca_cv[i], fp_test_pca_cv[i], fn_test_pca_cv[i], tp_test_pca_cv[i] = conf_matrix_test.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fffd0dc9-d78b-45f1-b37a-6c19e2c971e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table_pca_cv = pd.DataFrame({\n",
    "    'Scoring metric for CV': scoring_metrics,\n",
    "    'Learning_rate': best_lr_pca_cv,\n",
    "    'Max_depth': best_depth_pca_cv,\n",
    "    'Accuracy': accuracies_train_pca_cv,\n",
    "    'Contamination': contaminations_train_pca_cv,\n",
    "    'Completeness': completenesses_train_pca_cv,\n",
    "    'True positives': tp_train_pca_cv,\n",
    "    'False positives': fp_train_pca_cv,\n",
    "    'False negatives': fn_train_pca_cv,\n",
    "    'True negatives': tn_train_pca_cv\n",
    "})\n",
    "\n",
    "train_table_pca_cv[['Learning_rate', 'Accuracy', 'Contamination', 'Completeness']] = train_table_pca_cv[['Learning_rate', 'Accuracy', 'Contamination', 'Completeness']].round(3)\n",
    "train_table_pca_cv[['Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']] = train_table_pca_cv[['Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_table_pca_cv = pd.DataFrame({\n",
    "    'Scoring metric for CV': scoring_metrics,\n",
    "    'Learning_rate': best_lr_pca_cv,\n",
    "    'Max_depth': best_depth_pca_cv,\n",
    "    'Accuracy': accuracies_test_pca_cv,\n",
    "    'Contamination': contaminations_test_pca_cv,\n",
    "    'Completeness': completenesses_test_pca_cv,\n",
    "    'True positives': tp_test_pca_cv,\n",
    "    'False positives': fp_test_pca_cv,\n",
    "    'False negatives': fn_test_pca_cv,\n",
    "    'True negatives': tn_test_pca_cv\n",
    "    })\n",
    "\n",
    "test_table_pca_cv[['Learning_rate', 'Accuracy', 'Contamination', 'Completeness']] = test_table_pca_cv[['Learning_rate', 'Accuracy', 'Contamination', 'Completeness']].round(3)\n",
    "test_table_pca_cv[['Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']] = test_table_pca_cv[['Max_depth', 'True positives', 'False positives', 'False negatives', 'True negatives']].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcf8e6b5-90e8-4813-993f-782f56c4fcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Results of PCA boosting classification (cross-validated on learning_rate and max_depth) on train dataset:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scoring metric for CV</th>\n",
       "      <th>Learning_rate</th>\n",
       "      <th>Max_depth</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>True positives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "      <th>True negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.925</td>\n",
       "      <td>9268</td>\n",
       "      <td>531</td>\n",
       "      <td>754</td>\n",
       "      <td>59447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contamination</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.711</td>\n",
       "      <td>7121</td>\n",
       "      <td>452</td>\n",
       "      <td>2901</td>\n",
       "      <td>59526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Completeness</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.955</td>\n",
       "      <td>9567</td>\n",
       "      <td>313</td>\n",
       "      <td>455</td>\n",
       "      <td>59665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scoring metric for CV  Learning_rate  Max_depth  Accuracy  Contamination  \\\n",
       "0              Accuracy           0.50          3     0.982          0.054   \n",
       "1         Contamination           0.01          5     0.952          0.060   \n",
       "2          Completeness           0.50          4     0.989          0.032   \n",
       "\n",
       "   Completeness  True positives  False positives  False negatives  \\\n",
       "0         0.925            9268              531              754   \n",
       "1         0.711            7121              452             2901   \n",
       "2         0.955            9567              313              455   \n",
       "\n",
       "   True negatives  \n",
       "0           59447  \n",
       "1           59526  \n",
       "2           59665  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Results of PCA boosting classification (cross-validated on learning_rate and max_depth) on test dataset:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scoring metric for CV</th>\n",
       "      <th>Learning_rate</th>\n",
       "      <th>Max_depth</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>True positives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "      <th>True negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.893</td>\n",
       "      <td>3895</td>\n",
       "      <td>394</td>\n",
       "      <td>465</td>\n",
       "      <td>25246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contamination</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.705</td>\n",
       "      <td>3072</td>\n",
       "      <td>239</td>\n",
       "      <td>1288</td>\n",
       "      <td>25401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Completeness</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.898</td>\n",
       "      <td>3917</td>\n",
       "      <td>359</td>\n",
       "      <td>443</td>\n",
       "      <td>25281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scoring metric for CV  Learning_rate  Max_depth  Accuracy  Contamination  \\\n",
       "0              Accuracy           0.50          3     0.971          0.092   \n",
       "1         Contamination           0.01          5     0.949          0.072   \n",
       "2          Completeness           0.50          4     0.973          0.084   \n",
       "\n",
       "   Completeness  True positives  False positives  False negatives  \\\n",
       "0         0.893            3895              394              465   \n",
       "1         0.705            3072              239             1288   \n",
       "2         0.898            3917              359              443   \n",
       "\n",
       "   True negatives  \n",
       "0           25246  \n",
       "1           25401  \n",
       "2           25281  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"### Results of PCA boosting classification (cross-validated on learning_rate and max_depth) on train dataset:\"))\n",
    "display(train_table_pca_cv)\n",
    "\n",
    "display(Markdown(\"### Results of PCA boosting classification (cross-validated on learning_rate and max_depth) on test dataset:\"))\n",
    "display(test_table_pca_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd41275-45a9-4ec5-a300-a29a460b73cb",
   "metadata": {},
   "source": [
    "The results are very good, but slighty worse than the ones obtained without PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d047f6c4-88d5-498c-a797-820398045213",
   "metadata": {},
   "source": [
    "\n",
    "## Summary of results - best classifier\n",
    "\n",
    "The best classifier is confirmed to be the boosting one, without PCA: for max_depth = $4$ and learning_rate = $0.5$, it reached an accuracy of $\\sim97.4\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15b967b0-ec54-4315-ab39-30b461b4c8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scoring metric for CV</th>\n",
       "      <th>Learning_rate</th>\n",
       "      <th>Max_depth</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>True positives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "      <th>True negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.901</td>\n",
       "      <td>3930</td>\n",
       "      <td>351</td>\n",
       "      <td>430</td>\n",
       "      <td>25289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contamination</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.713</td>\n",
       "      <td>3108</td>\n",
       "      <td>236</td>\n",
       "      <td>1252</td>\n",
       "      <td>25404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Completeness</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.901</td>\n",
       "      <td>3930</td>\n",
       "      <td>351</td>\n",
       "      <td>430</td>\n",
       "      <td>25289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scoring metric for CV  Learning_rate  Max_depth  Accuracy  Contamination  \\\n",
       "0              Accuracy           0.50          4     0.974          0.082   \n",
       "1         Contamination           0.01          5     0.950          0.071   \n",
       "2          Completeness           0.50          4     0.974          0.082   \n",
       "\n",
       "   Completeness  True positives  False positives  False negatives  \\\n",
       "0         0.901            3930              351              430   \n",
       "1         0.713            3108              236             1252   \n",
       "2         0.901            3930              351              430   \n",
       "\n",
       "   True negatives  \n",
       "0           25289  \n",
       "1           25404  \n",
       "2           25289  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(test_table_boo2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
